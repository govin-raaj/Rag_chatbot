{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4071a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "from typing import Annotated, Any, Dict, Optional, TypedDict\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import InMemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75ff73a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.config import Config\n",
    "llm = ChatGroq(\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        api_key=Config.qroq_api_key,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f670c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = DuckDuckGoSearchRun(region=\"us-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05bb958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../data/attention_is_all_you_need_Paper.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "documents= loader.load()\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5963bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "docs=process_documents(documents)\n",
    "\n",
    "vector_Store= FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3aca2fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='8c068b8e-c530-410f-b253-84719302506e', metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '../data/attention_is_all_you_need_Paper.pdf', 'total_pages': 11, 'page': 6, 'page_label': '7'}, page_content='convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece'),\n",
       " Document(id='a9101095-8689-4408-8338-4f1554a4b7ed', metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '../data/attention_is_all_you_need_Paper.pdf', 'total_pages': 11, 'page': 9, 'page_label': '10'}, page_content='2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10'),\n",
       " Document(id='ee4b94fd-ab0a-4e07-8b32-1b9e25b0d2bd', metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '../data/attention_is_all_you_need_Paper.pdf', 'total_pages': 11, 'page': 3, 'page_label': '4'}, page_content='we found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\\ni=1 qiki, has mean 0 and variance dk.\\n4')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vector_Store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever.invoke(\"what is attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcd729c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def rag_tool(query: str,retriever) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the uploaded PDF document.\n",
    "   \n",
    "    \"\"\"\n",
    "    retriever =retriever\n",
    "    if retriever is None:\n",
    "        return {\n",
    "            \"error\": \"No document indexed for this chat. Upload a PDF first.\",\n",
    "            \"query\": query,\n",
    "        }\n",
    "\n",
    "    result = retriever.invoke(query)\n",
    "    context = [doc.page_content for doc in result]\n",
    "    metadata = [doc.metadata for doc in result]\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"context\": context,\n",
    "        \"metadata\": metadata,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86b7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is attention',\n",
       " 'context': ['convolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5 Training\\nThis section describes the training regime for our models.\\n5.1 Training Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [ 3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the signiﬁcantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece',\n",
       "  '2017.\\n[16] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[18] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n10',\n",
       "  'we found it beneﬁcial to linearly project the queries, keys and values htimes with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\noutput values. These are concatenated and once again projected, resulting in the ﬁnal values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = ∑dk\\ni=1 qiki, has mean 0 and variance dk.\\n4'],\n",
       " 'metadata': [{'producer': 'PyPDF2',\n",
       "   'creator': 'PyPDF',\n",
       "   'creationdate': '',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'publisher': 'Curran Associates, Inc.',\n",
       "   'language': 'en-US',\n",
       "   'created': '2017',\n",
       "   'eventtype': 'Poster',\n",
       "   'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'date': '2017',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'published': '2017',\n",
       "   'type': 'Conference Proceedings',\n",
       "   'firstpage': '5998',\n",
       "   'book': 'Advances in Neural Information Processing Systems 30',\n",
       "   'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)',\n",
       "   'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett',\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'lastpage': '6008',\n",
       "   'source': '../data/attention_is_all_you_need_Paper.pdf',\n",
       "   'total_pages': 11,\n",
       "   'page': 6,\n",
       "   'page_label': '7'},\n",
       "  {'producer': 'PyPDF2',\n",
       "   'creator': 'PyPDF',\n",
       "   'creationdate': '',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'publisher': 'Curran Associates, Inc.',\n",
       "   'language': 'en-US',\n",
       "   'created': '2017',\n",
       "   'eventtype': 'Poster',\n",
       "   'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'date': '2017',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'published': '2017',\n",
       "   'type': 'Conference Proceedings',\n",
       "   'firstpage': '5998',\n",
       "   'book': 'Advances in Neural Information Processing Systems 30',\n",
       "   'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)',\n",
       "   'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett',\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'lastpage': '6008',\n",
       "   'source': '../data/attention_is_all_you_need_Paper.pdf',\n",
       "   'total_pages': 11,\n",
       "   'page': 9,\n",
       "   'page_label': '10'},\n",
       "  {'producer': 'PyPDF2',\n",
       "   'creator': 'PyPDF',\n",
       "   'creationdate': '',\n",
       "   'subject': 'Neural Information Processing Systems http://nips.cc/',\n",
       "   'publisher': 'Curran Associates, Inc.',\n",
       "   'language': 'en-US',\n",
       "   'created': '2017',\n",
       "   'eventtype': 'Poster',\n",
       "   'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.',\n",
       "   'title': 'Attention is All you Need',\n",
       "   'date': '2017',\n",
       "   'moddate': '2018-02-12T21:22:10-08:00',\n",
       "   'published': '2017',\n",
       "   'type': 'Conference Proceedings',\n",
       "   'firstpage': '5998',\n",
       "   'book': 'Advances in Neural Information Processing Systems 30',\n",
       "   'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)',\n",
       "   'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett',\n",
       "   'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin',\n",
       "   'lastpage': '6008',\n",
       "   'source': '../data/attention_is_all_you_need_Paper.pdf',\n",
       "   'total_pages': 11,\n",
       "   'page': 3,\n",
       "   'page_label': '4'}]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_tool(\"what is attention\",retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72681f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "163ce7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [rag_tool, search_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd87f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_node(state: ChatState, config=None):\n",
    "    \"\"\"LLM node that may answer or request a tool call.\"\"\"\n",
    "\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful assistant. For questions about the uploaded PDF, call \"\n",
    "            \"the `rag_tool` . You can also use the web search tool when helpful. \"\n",
    "            \"If no document is available, ask the user \"\n",
    "            \"to upload a PDF.\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "\n",
    "    messages = [system_message, *state[\"messages\"]]\n",
    "    response = llm_with_tools.invoke(messages, config=config)\n",
    "    return {\"messages\": [response]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86951ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e86f2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = InMemorySaver()\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2a7187b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000018217CF4A90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f1a0d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "CONFIG = {'configurable': {'thread_id': 'thread-1'}}\n",
    "response=chatbot.invoke({\"messages\": [HumanMessage(content=\"whats my name\")]}, config=CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db89e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is attemtion is all you need?', additional_kwargs={}, response_metadata={}, id='ef5715c4-54a4-47ff-85ea-86f38cdeb684'),\n",
       "  HumanMessage(content='hi i m raaj', additional_kwargs={}, response_metadata={}, id='b6f40f9d-a09f-4ca6-814d-23a570c84019'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '1atdr3qc9', 'function': {'arguments': '{\"query\":\"Attention Is All You Need\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 396, 'total_tokens': 417, 'completion_time': 0.062664661, 'completion_tokens_details': None, 'prompt_time': 0.020438461, 'prompt_tokens_details': None, 'queue_time': 0.057012999, 'total_time': 0.083103122}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--246e4b0a-ce61-4806-aac2-0490659fcec5-0', tool_calls=[{'name': 'duckduckgo_search', 'args': {'query': 'Attention Is All You Need'}, 'id': '1atdr3qc9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 396, 'output_tokens': 21, 'total_tokens': 417}),\n",
       "  ToolMessage(content='\" Attention Is All You Need \" [1] is a 2017 landmark [2][3] research paper in machine learning authored by eight scientists working at Google. Jun 12, 2017 · View a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors Aug 8, 2025 · What’s the motivation behind this? The Transformer architecture, introduced in “Attention Is All You Need,” emerged from a need to address fundamental limitations in … May 6, 2025 · • Divides the self-attention mechanism into multiple parallel “heads,” each with its own learned linear projection of queries, keys, and values. • Each attention head can … Feb 12, 2025 · By replacing recurrence with self-attention mechanisms, the authors introduced the Transformer architecture, a design that enabled parallelized training, captured long-range …', name='duckduckgo_search', id='97524f16-a416-43a3-8235-f8032f1dfbab', tool_call_id='1atdr3qc9'),\n",
       "  AIMessage(content='The paper \"Attention Is All You Need\" introduced the Transformer architecture, which replaced recurrence with self-attention mechanisms, enabling parallelized training and capturing long-range dependencies. The Transformer architecture has been widely adopted in natural language processing and other fields.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 610, 'total_tokens': 659, 'completion_time': 0.102130032, 'completion_tokens_details': None, 'prompt_time': 0.036260273, 'prompt_tokens_details': None, 'queue_time': 0.057356746, 'total_time': 0.138390305}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--00408625-e9af-436a-86f9-cc5fbdf7d61c-0', usage_metadata={'input_tokens': 610, 'output_tokens': 49, 'total_tokens': 659}),\n",
       "  HumanMessage(content='hi i m raaj', additional_kwargs={}, response_metadata={}, id='20a0d8bc-2a2e-42fb-ad2b-7427d93482d9'),\n",
       "  AIMessage(content=\"Hello Raaj! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 673, 'total_tokens': 700, 'completion_time': 0.071909803, 'completion_tokens_details': None, 'prompt_time': 0.033044626, 'prompt_tokens_details': None, 'queue_time': 0.052778124, 'total_time': 0.104954429}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_68f543a7cc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--004a52a6-fb97-469b-bbd3-fbd8c2f90b09-0', usage_metadata={'input_tokens': 673, 'output_tokens': 27, 'total_tokens': 700}),\n",
       "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}, id='ed0f3108-09cb-4cd7-9cbe-d432af192cbb'),\n",
       "  AIMessage(content='Your name is Raaj.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 713, 'total_tokens': 720, 'completion_time': 0.017117385, 'completion_tokens_details': None, 'prompt_time': 0.045077069, 'prompt_tokens_details': None, 'queue_time': 0.053095811, 'total_time': 0.062194454}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e00d79b2-564f-4f09-bfea-9584cdb61ebb-0', usage_metadata={'input_tokens': 713, 'output_tokens': 7, 'total_tokens': 720}),\n",
       "  HumanMessage(content='whats my name', additional_kwargs={}, response_metadata={}, id='3e61821a-2a53-41f0-b2fc-8ce1a47cb9fa'),\n",
       "  AIMessage(content='Your name is Raaj.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 733, 'total_tokens': 740, 'completion_time': 0.017948839, 'completion_tokens_details': None, 'prompt_time': 0.046611209, 'prompt_tokens_details': None, 'queue_time': 0.057943701, 'total_time': 0.064560048}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b2a9d33d-9024-4800-9ec4-109b9e5d9b27-0', usage_metadata={'input_tokens': 733, 'output_tokens': 7, 'total_tokens': 740})]}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606cb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional, Callable\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langchain_core.tools import tool as tool_decorator\n",
    "from app.config import Config\n",
    "from app.logger import logging\n",
    "\n",
    "\n",
    "def rag_tool_impl(retriever: Any, query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Pure function implementing the RAG logic (no @tool decoration).\"\"\"\n",
    "    if retriever is None:\n",
    "        return {\n",
    "            \"error\": \"No document indexed for this chat. Upload a PDF first.\",\n",
    "            \"query\": query,\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        results = retriever.get_relevant_documents(query)\n",
    "    except AttributeError:\n",
    "        try:\n",
    "            results = retriever.invoke(query)\n",
    "        except Exception as e:\n",
    "            logging.exception(\"Retriever invocation failed: %s\", e)\n",
    "            return {\"error\": \"Retriever invocation failed.\", \"detail\": str(e)}\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Retriever failed: %s\", e)\n",
    "        return {\"error\": \"Retriever failed.\", \"detail\": str(e)}\n",
    "\n",
    "    context = [getattr(doc, \"page_content\", str(doc)) for doc in results]\n",
    "    metadata = [getattr(doc, \"metadata\", {}) for doc in results]\n",
    "\n",
    "    return {\"query\": query, \"context\": context, \"metadata\": metadata}\n",
    "\n",
    "\n",
    "class LLmService:\n",
    "    class chatState(TypedDict):\n",
    "        messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "    def __init__(self, vector_store, query: str):\n",
    "        logging.info(\"Initializing LLM Service.\")\n",
    "        self.query = query\n",
    "        self.vector_store = vector_store\n",
    "\n",
    "        # initialize LLM\n",
    "        self.llm = ChatGroq(\n",
    "            model_name=\"llama-3.3-70b-versatile\",\n",
    "            api_key=Config.qroq_api_key,\n",
    "        )\n",
    "\n",
    "        # Retriever (if available)\n",
    "        self.retriever = None\n",
    "        try:\n",
    "            if vector_store and hasattr(vector_store, \"vector_store\"):\n",
    "                self.retriever = vector_store.vector_store.as_retriever(\n",
    "                    search_type=\"similarity\", search_kwargs={\"k\": 4}\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logging.exception(\"Failed to create retriever from vector_store: %s\", e)\n",
    "            self.retriever = None\n",
    "\n",
    "        # Tools: web search and RAG tool (rag_tool is instance method)\n",
    "        self.search_tool = DuckDuckGoSearchRun(region=\"us-en\")\n",
    "\n",
    "        def _rag_closure(tool_input: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "            \"\"\"RAG tool: return nearest documents for the current query using the provided retriever.\"\"\"\n",
    "            return rag_tool_impl(self.retriever, self.query)\n",
    "\n",
    "       \n",
    "        self.rag_tool = tool_decorator(_rag_closure)\n",
    "\n",
    "        # Now the tools list contains tool objects (not the result of calling them).\n",
    "        self.tools = [self.rag_tool, self.search_tool]\n",
    "\n",
    "        # Bind tools to the LLM (safe)\n",
    "        self.llm_with_tools = self.llm.bind_tools(self.tools)\n",
    "\n",
    "        # Build LangGraph nodes and graph in __init__\n",
    "        self.tool_node = ToolNode(self.tools)\n",
    "\n",
    "        self.checkpointer = InMemorySaver()\n",
    "        \n",
    "        self.graph = StateGraph(self.chatState)\n",
    "        self.graph.add_node(\"chat_node\", self.chat_node)\n",
    "        self.graph.add_node(\"tools\", self.tool_node)\n",
    "        \n",
    "        self.graph.add_edge(START, \"chat_node\")\n",
    "        self.graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "        self.graph.add_edge(\"tools\", \"chat_node\")\n",
    "        \n",
    "        self.chatbot = self.graph.compile(checkpointer=self.checkpointer)\n",
    "\n",
    "    # RAG tool implemented as an instance method; decorated with @tool\n",
    "\n",
    "\n",
    "    def chat_node(self, state: chatState, config=None) -> Dict[str, List[BaseMessage]]:\n",
    "        \"\"\"LLM node that may answer or request a tool call.\"\"\"\n",
    "        system_message = SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant. For questions about the uploaded PDF, call \"\n",
    "                \"the `rag_tool`. You can also use the web search tool when helpful. \"\n",
    "                \"If no document is available, ask the user to upload a PDF.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        messages = [system_message, *state[\"messages\"]]\n",
    "        try:\n",
    "            # llm_with_tools is bound LLM that can call tools\n",
    "            response = self.llm_with_tools.invoke(messages, config=config)\n",
    "        except Exception as e:\n",
    "            logging.exception(\"LLM invocation failed: %s\", e)\n",
    "            # Return an error message wrapped as a system message (or format as your app expects)\n",
    "            return {\"messages\": [SystemMessage(content=f\"LLM invocation error: {e}\")]}\n",
    "\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # Optionally expose a convenience run method to call the compiled chatbot\n",
    "    def run(self, initial_messages: List[BaseMessage]):\n",
    "        # The graph expects a specific state format; adapt as necessary\n",
    "        CONFIG = {'configurable': {'thread_id': 'thread-1'}}\n",
    "        state: LLmService.chatState = {\"messages\": initial_messages}\n",
    "        return self.chatbot.invoke(state,config=CONFIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1293f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict, List, Dict, Any\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from typing import Annotated, TypedDict, List, Dict, Any, Optional, Callable\n",
    "from langchain_core.messages import BaseMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from app.vector_store.vector_store import VectorStore\n",
    "from app.config import Config\n",
    "from app.logger import logging\n",
    "\n",
    "\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "        messages: Annotated[list[BaseMessage], add_messages]\n",
    "\n",
    "llm = ChatGroq(\n",
    "        model_name=\"llama-3.3-70b-versatile\",\n",
    "        api_key=Config.qroq_api_key,\n",
    "        )\n",
    "\n",
    "vector_store=VectorStore()\n",
    "\n",
    "\n",
    "\n",
    "def chat_node(state: ChatState, config=None):\n",
    "    \"\"\"LLM node that may answer or request a tool call.\"\"\"\n",
    "    thread_id = \"thread_1\"\n",
    "    system_message = SystemMessage(\n",
    "        content=(\n",
    "            \"You are a helpful assistant. For questions about the uploaded PDF, call \"\n",
    "            \"the `rag_tool` and include the thread_id \"\n",
    "            f\"`{thread_id}`.\"\n",
    "            \"If no document is available, ask the user \"\n",
    "            \"to upload a PDF.\"\n",
    "        )\n",
    "    )\n",
    "    messages = [system_message, *state[\"messages\"]]\n",
    "    response = llm_with_tools.invoke(messages, config=config)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "@tool\n",
    "def rag_tool(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Retrieve relevant information from the uploaded PDF(s).\n",
    "    \"\"\"\n",
    "    # ensure vectorstore has been initialized and loaded\n",
    "    if vector_store.vector_store is None:\n",
    "        return {\n",
    "            \"error\": \"No document indexed for this chat. Upload a PDF first.\",\n",
    "            \"query\": query,\n",
    "        }\n",
    "\n",
    "    # Use the retriever interface if available, else fallback to similarity_search\n",
    "    try:\n",
    "        retr = vector_store.vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "        docs = retr.get_relevant_documents(query)  # if your retriever has this method\n",
    "    except Exception:\n",
    "        # fallback: call similarity_search directly (works with LangChain FAISS wrapper)\n",
    "        docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "    context = [getattr(d, \"page_content\", str(d)) for d in docs]\n",
    "    metadata = [getattr(d, \"metadata\", {}) for d in docs]\n",
    "\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"context\": context,\n",
    "        \"metadata\": metadata,\n",
    "    }\n",
    "\n",
    "\n",
    "# search_tool = DuckDuckGoSearchRun(region=\"us-en\")\n",
    "tools = [ rag_tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "\n",
    "graph = StateGraph(ChatState)\n",
    "graph.add_node(\"chat_node\", chat_node)\n",
    "graph.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph.add_edge(START, \"chat_node\")\n",
    "graph.add_conditional_edges(\"chat_node\", tools_condition)\n",
    "graph.add_edge(\"tools\", \"chat_node\")\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
