# ğŸ¤– RAG Chatbot â€“ FastAPI | LangChain | Groq | HuggingFace | FAISS

An end-to-end RAG (Retrieval-Augmented Generation) system demonstrating modern AI engineering practices â€” from document ingestion, text chunking, embedding generation, vector storage, semantic search, conversational response generation, Dockerization, CI/CD, to AWS EC2 deployment.

This project is designed not only as a functional RAG system, but as a portfolio showcase demonstrating:

âœ… **AI Engineering** (LLM orchestration, embedding models, vector search)  
âœ… **Backend Development** (FastAPI, routing, file handling, HTML templating)  
âœ… **MLOps / LLMOps** (CI/CD, ECR push, EC2 deployment, Docker)  
âœ… **Cloud & DevOps** (AWS EC2, ECR, IAM, GitHub Actions runners)  
âœ… **Software Engineering** (logging, modular structure, environment config)

---

## ğŸ“‚ Project Structure
```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                     # FastAPI application entrypoint
â”‚   â”œâ”€â”€ config.py                   # Environment & API config
â”‚   â”œâ”€â”€ logger.py                   # Application-wide logging
â”‚   â”œâ”€â”€ templates/                  # Jinja2 HTML templates
â”‚   â”œâ”€â”€ static/                     # CSS/JS frontend assets
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚     â””â”€â”€ data_processing.py    # PDF/Text loading + text splitting
â”‚   â”œâ”€â”€ vector_store/
â”‚   â”‚     â””â”€â”€ vector_store.py       # FAISS and embeddings management
â”‚
â”œâ”€â”€ uploads/                        # Uploaded user files
â”œâ”€â”€ Dockerfile                      # Docker build configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .github/workflows/deploy.yml    # CI/CD Pipeline
â””â”€â”€ README.md
```


## ğŸ“„ Document Ingestion Pipeline

 **This project supports PDF and text file ingestion:**
 **âœ” Extraction & Processing Steps**
* Upload PDF/TXT files via UI
* Extract raw text
* Apply RecursiveCharacterTextSplitter
* Generate embeddings using:
* sentence-transformers/all-MiniLM-L6-v2
* Store embeddings in FAISS vector store
* Automatically retrieve relevant chunks during user queries



## ğŸ” Conversational Retrieval Chain

**The chatbot uses:**
* Groq LLM (LLaMA 3, Mixtral) for response generation
* LangChain for routing messages, tool composition, and state graph
* FAISS for relevant passage retrieval



## ğŸ“ Logging & Error Handling

**Integrated logging supports:**
* File upload logging
* PDF parsing failures
* Embedding pipeline tracking
* Query tracing and LLM response logging




## â˜ï¸ AWS Deployment (CI/CD)

**Your project includes a complete CI/CD pipeline using GitHub Actions.**

**Workflow tasks:**
* Build Docker image
* Push to AWS ECR
* Trigger deployment job
* EC2 (self-hosted runner) pulls latest image
* Restarts container with new version


## ğŸ”‘ Required GitHub Secrets

* AWS_ACCESS_KEY_ID
* AWS_SECRET_ACCESS_KEY
* AWS_DEFAULT_REGION
* ECR_REPO
* GROQ_API_KEY




## ğŸ“Š Features Summary
* âœ… RAG-based Question Answering
* âœ… PDF/Text file uploads
* âœ… FAISS-based semantic search
* âœ… Groq-powered LLM responses
* âœ… Modular architecture
* âœ… Dockerized backend
* âœ… GitHub Actions CI/CD
* âœ… AWS EC2 deploymen* 







